{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 튜토리얼에서는 문서를 한 벡터 표현에서 다른 벡터 표현으로 변환하는 방법을 보여드리겠습니다. 이 과정은 두 가지 목표를 가지고 있습니다:\n",
    "\n",
    "\t1.\t말뭉치에서 숨겨진 구조를 드러내고, 단어 간의 관계를 발견하여 문서를 새롭고 (희망적으로) 더 의미 있는 방식으로 설명하는 것입니다.\n",
    "\t2.\t문서 표현을 더 간결하게 만들어 효율성을 향상시키고 (새로운 표현이 적은 자원을 소비함) 효과성을 높이는 것입니다 (마이너 데이터 경향을 무시하고 노이즈를 줄입니다).\n",
    "\n",
    "말뭉치 생성\n",
    "\n",
    "먼저, 작업할 말뭉치를 만들어야 합니다. 이 단계는 이전 튜토리얼과 동일하며, 이미 완료했다면 다음 섹션으로 건너뛰어도 괜찮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an LSI transformation\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) #차원수 2\n",
    "\n",
    "# create a double wrapper over the original corpus : bow->tfidf->fold-in-lsi\n",
    "corpus_lsi = lsi_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topics\n",
    "lsi_model.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066007833960907), (1, -0.5200703306361851)] Human machine interface for lab abc computer applications\n",
      "[(0, 0.19667592859142932), (1, -0.7609563167700032)] A survey of user opinion of computer system response time\n",
      "[(0, 0.08992639972446861), (1, -0.7241860626752511)] The EPS user interface management system\n",
      "[(0, 0.07585847652178528), (1, -0.632055158600343)] System and human system engineering testing of EPS\n",
      "[(0, 0.10150299184980437), (1, -0.5737308483002944)] Relation of user perceived response time to error measurement\n",
      "[(0, 0.70321089393783), (1, 0.16115180214026137)] The generation of random binary unordered trees\n",
      "[(0, 0.877478767311982), (1, 0.16758906864659862)] The intersection graph of paths in trees\n",
      "[(0, 0.9098624686818569), (1, 0.140865536287195)] Graph minors IV Widths of trees and well quasi ordering\n",
      "[(0, 0.6165825350569283), (1, -0.053929075663890116)] Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "#Document vector\n",
    "#both bow->tfidf and tfidf ->lsi transformations are actually executed here, on the fly.\n",
    "for doc, as_text in zip(corpus_lsi, documents):\n",
    "    print (doc, as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59363762, 1.47629312])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# singular value\n",
    "lsi_model.projection.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04940859, -0.29287972],\n",
       "       [ 0.02969616, -0.2804038 ],\n",
       "       [ 0.03522417, -0.32750471],\n",
       "       [ 0.05951239, -0.3204961 ],\n",
       "       [ 0.1869311 , -0.17065511],\n",
       "       [ 0.06135723, -0.46024666],\n",
       "       [ 0.05951239, -0.3204961 ],\n",
       "       [ 0.05823724, -0.3726838 ],\n",
       "       [ 0.03490897, -0.3323675 ],\n",
       "       [ 0.70321089,  0.1611518 ],\n",
       "       [ 0.53773148,  0.07585493],\n",
       "       [ 0.40171367,  0.0294099 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word vector(left singular vectors)\n",
    "lsi_model.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer',\n",
       " 'human',\n",
       " 'interface',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'system',\n",
       " 'time',\n",
       " 'user',\n",
       " 'eps',\n",
       " 'trees',\n",
       " 'graph',\n",
       " 'minors']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Words\n",
    "words = [dictionary.id2token[i] for i in range(len(dictionary))]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer', array([ 0.04940859, -0.29287972])),\n",
       " ('human', array([ 0.02969616, -0.2804038 ])),\n",
       " ('interface', array([ 0.03522417, -0.32750471])),\n",
       " ('response', array([ 0.05951239, -0.3204961 ])),\n",
       " ('survey', array([ 0.1869311 , -0.17065511])),\n",
       " ('system', array([ 0.06135723, -0.46024666])),\n",
       " ('time', array([ 0.05951239, -0.3204961 ])),\n",
       " ('user', array([ 0.05823724, -0.3726838 ])),\n",
       " ('eps', array([ 0.03490897, -0.3323675 ])),\n",
       " ('trees', array([0.70321089, 0.1611518 ])),\n",
       " ('graph', array([0.53773148, 0.07585493])),\n",
       " ('minors', array([0.40171367, 0.0294099 ]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Vector\n",
    "list(zip(words, lsi_model.projection.u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066007833960907), (1, -0.5200703306361851)]\n",
      "[(0, 0.19667592859142932), (1, -0.7609563167700032)]\n",
      "[(0, 0.08992639972446861), (1, -0.7241860626752511)]\n",
      "[(0, 0.07585847652178528), (1, -0.632055158600343)]\n",
      "[(0, 0.10150299184980437), (1, -0.5737308483002944)]\n",
      "[(0, 0.70321089393783), (1, 0.16115180214026137)]\n",
      "[(0, 0.877478767311982), (1, 0.16758906864659862)]\n",
      "[(0, 0.9098624686818569), (1, 0.140865536287195)]\n",
      "[(0, 0.6165825350569283), (1, -0.053929075663890116)]\n"
     ]
    }
   ],
   "source": [
    "#Document vector(Right singular vectors)\n",
    "for doc in corpus_lsi:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
